c(
splinefun1(x, i=1, m=2, tau=knots),
splinefun1(x, i=2, m=2, tau=knots),
splinefun1(x, i=3, m=2, tau=knots),
splinefun1(x, i=4, m=2, tau=knots),
splinefun1(x, i=5, m=2, tau=knots),
splinefun1(x, i=6, m=2, tau=knots),
splinefun1(x, i=7, m=2, tau=knots),
splinefun1(x, i=8, m=2, tau=knots),
splinefun1(x, i=9, m=2, tau=knots)
),
nrow=length(x),
ncol=9
)
fn3 = matrix(
c(
splinefun1(x, i=1, m=3, tau=knots),
splinefun1(x, i=2, m=3, tau=knots),
splinefun1(x, i=3, m=3, tau=knots),
splinefun1(x, i=4, m=3, tau=knots),
splinefun1(x, i=5, m=3, tau=knots),
splinefun1(x, i=6, m=3, tau=knots),
splinefun1(x, i=7, m=3, tau=knots),
splinefun1(x, i=8, m=3, tau=knots)
),
nrow=length(x),
ncol=8
)
fn4 = matrix(
c(
splinefun1(x, i=1, m=4, tau=knots),
splinefun1(x, i=2, m=4, tau=knots),
splinefun1(x, i=3, m=4, tau=knots),
splinefun1(x, i=4, m=4, tau=knots),
splinefun1(x, i=5, m=4, tau=knots),
splinefun1(x, i=6, m=4, tau=knots),
splinefun1(x, i=7, m=4, tau=knots)
),
nrow=length(x),
ncol=7
)
bs_2 = splinefun2(x, tau=knots, m=2, i=2:(length(knots)-1))
bs_3 = splinefun2(x, tau=knots, m=3, i=3:(length(knots)-1))
bs_4 = splinefun2(x, tau=knots, m=4, i=4:(length(knots)-1))
bb1 <- splinefun3(x, tau=knots, m=1, i=1:(length(knots) - 1))
bb2 <- splinefun3(x, tau=knots, m=2, i=1:(length(knots) - 2))
bb3 <- splinefun3(x, tau=knots, m=3, i=1:(length(knots) - 3))
bb4 <- splinefun3(x, tau=knots, m=4, i=1:(length(knots) - 4))
# splinefun1
layout(matrix(1:12, ncol=3, byrow=FALSE))
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=1")
matlines(x, fn1, ylim = c(0,1), lty = 1)
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=2")
matlines(x, fn2, ylim = c(0,1), lty = 1)
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=3")
matlines(x, fn3, ylim = c(0,1), lty = 1)
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=4")
matlines(x, fn4, ylim = c(0,1), lty = 1)
# splinefun2
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=1")
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=2")
matlines(x, bs_2, ylim = c(0,1), lty = 1)
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=3")
matlines(x, bs_3, ylim = c(0,1), lty = 1)
plot(1, type = "n", xlab = "", ylab = "", xlim = c(0, 1), ylim = c(0, 1), main="order=4")
matlines(x, bs_4, ylim = c(0,1), lty = 1)
# splinefun3
plot(range(x), c(0,1), type = "n", xlab = "x", ylab = "", main="order=1")
matlines(x, bb1, ylim = c(0,1), lty = 1)
plot(range(x), c(0,1), type = "n", xlab = "x", ylab = "", main="order=2")
matlines(x, bb2, ylim = c(0,1), lty = 1)
plot(range(x), c(0,1), type = "n", xlab = "x", ylab = "", main="order=3")
matlines(x, bb3, ylim = c(0,1), lty = 1)
plot(range(x), c(0,1), type = "n", xlab = "x", ylab = "", main="order=4")
matlines(x, bb4, ylim = c(0,1), lty = 1)
## Question 2e)
library(gamair) # Datasets from the GAM book
data(chicago)
chicago$ldeath <- log(chicago$death) # log transform the counts
par(mfrow=c(1,2))
with(chicago, plot(ldeath~time, pch='.'))
with(chicago, plot(ldeath~pm10median,pch='.'))
# Ridge regression formula, from in-class lab
ridgeregression <- function(formula,data,lambda) {
# formula: R formula, like for lm()
# data: data.frame containing the variables present in formula
# lambda: numeric scalar > 0, penalization parameter
# construct the model matrix
# remove the intercept if present
# centre the covariates
X <- model.matrix(update.formula(formula,~.-1),data)
X <- sweep(X,2,colMeans(X),'-')
# compute beta
sizematrix <- crossprod(X) + diag(rep(lambda,ncol(X)))
betahat <- solve(sizematrix,crossprod(X,y))
# return a list containing the coefficients, variance matrix
list(
coef = c(mean(data$y),betahat),
vcov = solve(sizematrix) %*% crossprod(X) %*% solve(sizematrix)
)
}
par(mfrow=c(2, 1))
## f_1 plot:
x = chicago$time
y = chicago$ldeath
# Code to create the fitted b-spline + ridge regression model (from lab)
lam <- exp(1.5)
knots = seq(-2556.5, 2556.5, length.out=45)
ff <- y~bs(x,knots=knots)
mod <- ridgeregression(ff,data.frame(x=x,y=y),lam)
xx <- seq(min(x),max(x),length.out=1e03)
XX <- model.matrix(ff,data.frame(x=xx,y=rnorm(length(xx))))
XX <- sweep(XX,2,colMeans(XX),'-')
XX[ ,1] <- 1
ypred <- as.numeric(XX %*% mod$coef)
# Calculate the standard error of the prediciton using a padded
# variance-covariance matrix.
padded_cov = cbind(
rep(0, ncol(mod$vcov)+1),
rbind(rep(0, nrow(mod$vcov)), mod$vcov)
)
padded_cov[1,1] = var(chicago$ldeath)
se <- sqrt(diag(XX %*% padded_cov %*% t(XX)))
# Plot the lines
plot(x,y, pch='.', main="Fitted Model for f_1, lambda=exp(1.5), order=4", ylab="Log Death Count",
xlab="day number")
lines(xx,ypred,lty='dashed', col='red', lwd=1.5)
lines(xx,ypred -1.96*se,lty='dotted')
lines(xx,ypred +1.96*se,lty='dotted')
# Diagnostic (knot values and b-spline before ridge regression)
# abline(v=knots, lty='dotted', col='lightgrey', lwd=0.5)
# fm1 <- lm(ff)
# lines(xx, predict(fm1, data.frame(x=xx)), col='blue', lty='dotted')
## f_2 plot:
# Filter out NA values
chicago <- chicago[!is.na(chicago$pm10median), ]
x = chicago$pm10median
y = chicago$ldeath
# Code to create the fitted b-spline + ridge regression model (from lab)
lam <- exp(1)
knots = c(-38, 0, 25, 100, 325)
ff2 <- y~bs(x,knots=knots, degree=4)
mod <- ridgeregression(ff2,data.frame(x=x,y=y),lam)
se <- sqrt(diag(mod$vcov))
xx <- seq(min(x),max(x),length.out=1e03)
XX <- model.matrix(ff2,data.frame(x=xx,y=rnorm(length(xx))))
XX <- sweep(XX,2,colMeans(XX),'-')
XX[ ,1] <- 1
ypred <- as.numeric(XX %*% mod$coef)
# Calculate the standard error of the prediciton using a padded
# variance-covariance matrix.
padded_cov = cbind(
rep(0, ncol(mod$vcov)+1),
rbind(rep(0, nrow(mod$vcov)), mod$vcov)
)
padded_cov[1,1] = var(chicago$ldeath)
se <- sqrt(diag(XX %*% padded_cov %*% t(XX)))
# Plot the lines
plot(x,y, pch='.', main="Fitted Model for f_2, lambda=exp(1), order=4", ylab="Log Death Count",
xlab="Measured PM(10) (air pollution)")
lines(xx,ypred,lty='dashed', col='red', lwd=1.5)
lines(xx,ypred -1.96*se,lty='dotted')
lines(xx,ypred +1.96*se,lty='dotted')
# Diagnostic (knot values and b-spline before ridge regression)
# abline(v=knots, lty='dotted', col='grey')
# fm2 <- lm(ff2)
# lines(xx, predict(fm2, data.frame(x=xx)), col='blue', lty='dotted')
exp(1)
source("C:/Users/Angelo/Desktop/STAT 444 A2 R CODE.R", echo=TRUE)
library(knitr)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=70),tidy=TRUE)
data = data.frame(
x1=c(0,1,0,1),
x2=c(0,0,1,1),
y=c(22,54,40,60),
m=c(100, 100, 101, 99)
)
kable(data)
# construct the response variable for the logistic regression analysis
data$resp = cbind(data$y, data$m - data$y)
data
model1 = glm(resp ~ x1 + x2 + x1*x2, family=binomial(link=logit), data=data)
summary(model1)
data_rep = data.frame(
x1=rep(c(0,1), c(201,199)),
x2=rep(c(0,1,0,1), c(100, 101, 100, 99)),
y=rep(c(0,1,0,1,0,1,0,1), c(78, 22, 61, 40, 46, 54, 39, 60))
)
model2 = lm(y ~ x1 + x2 + x1*x2, data=data_rep)
summary(model2)
# create the indicator variables ("factors" in R) for x1 and x2
data$x1f = factor(data$x1)
data$x2f = factor(data$x2)
model3 = glm(resp ~ x1 + x2 + x1*x2, family=binomial(link="identity"), data=data)
summary(model3)
data = data.frame(
x1=c(1.34, 1.60, 1.75, 1.85, 1.95, 2.00, 2.14, 2.25, 2.34),
y=c(0, 0, 2, 5, 8, 20, 31, 49, 12),
m=c(13, 19, 69, 50, 79, 70, 66, 56, 13)
)
# construct the response variable for the logistic regression analysis
data$resp = cbind(data$y, data$m - data$y)
data
model1 = glm(data$resp ~ x1, family=binomial(link="logit"), data=data)
summary(model1)
model2 = glm(data$resp ~ x1, family=binomial(link="probit"), data=data)
summary(model2)
model3 = glm(data$resp ~ x1, family=binomial(link="cloglog"), data=data)
summary(model3)
model.array=rbind(coef(model1), coef(model2), coef(model3))
model.array=cbind(model.array, c(deviance(model1), deviance(model2), deviance(model3)))
colnames(model.array)=c("Intercept", "log(area+1)","Residual dev.")
rownames(model.array)=c("Logit","Probit","C log-log")
kable(model.array)
rd1 = residuals.glm(model1,"deviance")
fv1 = model1$fitted.values
rd2 = residuals.glm(model2,"deviance")
fv2 = model2$fitted.values
rd3 = residuals.glm(model3,"deviance")
fv3 = model3$fitted.values
plot(fv1,rd1,ylim=c(-4,4), xlab="FITTED VALUES",ylab="RESIDUALS",col=2,pch=16,cex=2)
points(fv2,rd2,col=3,pch=17,cex=2)
points(fv3,rd3,col=4,pch=18,cex=2)
abline(h=-2, lty=2)
abline(h= 2, lty=2)
legend(0,4.4,c("Model 1 Residuals","Model 2 Residuals","Model 3 Residuals"),pch=c(16,17,18), col=c(2,3,4), bty="n")
c(sum(rd1^2), sum(rd2^2), sum(rd3^2))
beta = as.vector(model3$coefficients)
delta = (log(0.1) - model3$coefficients[1])/model3$coefficients[2]
delta = (log(-log(1-0.1)) - beta[1])/beta[2]
1-exp(-exp(predict(model3, newdata=data.frame(x1=delta))))
odds = 1-exp(-exp(predict(model3)))
x = seq(0, 2.5, length.out = 100)
plot(odds ~ data$x1)
points(delta, 1-exp(-exp(predict(model3, newdata=data.frame(x1=delta)))), col="blue", lwd=5)
abline(h=0.1)
prob = as.vector(rep(1,length(x)))
for(i in 1:length(x)) {
prob[i] = 1 - exp( - exp(beta[1] + beta[2] * x[i]))
}
lines(x, prob, col='red')
# Save the original .csv file in your R Working Directory
# and then run this code block to input the data and
# prepare it for our analysis.
COVIDdata = read.csv("journal.pone.0245327.s010.csv")
# Limit the data to students from NCSU and a restricted set
# of explanatory variables
COVIDdata_NCSU = COVIDdata[(!is.na(COVIDdata$Source) & (COVIDdata$Source ==
"NCState")), names(COVIDdata) %in% c("Health_General", "Hrs_Screen",
"Hrs_Outdoor", "Hrs_Exercise", "Class_Self", "Infected_Any",
"BMI", "Educ_College_Grad", "Age", "Classification_High",
"Ethnoracial_Group_White1_Asian2", "Age_18to25")]
# Remove observations with missing Ethnoracial data (all
# other variable are complete)
COVIDdata_NCSU = COVIDdata_NCSU[!is.na(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2),
]
# clean up non-integer class values
COVIDdata_NCSU$Class_Self <- round(COVIDdata_NCSU$Class_Self)
# Create factor variables where necessary
COVIDdata_NCSU$Infected_Any = factor(COVIDdata_NCSU$Infected_Any)
COVIDdata_NCSU$Educ_College_Grad = factor(COVIDdata_NCSU$Educ_College_Grad)
COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2 = factor(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2)
COVIDdata_NCSU$Age_18to25 = factor(COVIDdata_NCSU$Age_18to25)
# str(COVIDdata_NCSU) # Display
# Fit a main effects logistic regression model
modelA = glm(Classification_High ~ Age + Ethnoracial_Group_White1_Asian2 + Class_Self + Health_General + BMI + Hrs_Screen + Hrs_Outdoor + Hrs_Exercise + Educ_College_Grad + Infected_Any, family = binomial(link = "logit"), data = COVIDdata_NCSU)
summary(modelA)
format(exp(modelA$coefficients), scientific=FALSE)
exp(-0.163984 + c(-1, 1) * 1.96 * 0.061946)
exp(0.444331 + c(-1, 1) * 1.96 * 0.138834)
exp(0.287848 + c(-1, 1) * 1.96 * 0.198502)
exp(0.439006 + c(-1, 1) * 1.96 * 0.233072)
z = (0.036405-0)/(0.145139)
2*(1 - pnorm(z))
var_b1 = summary(modelA)$cov.scaled[2, 2]
var_b2 = summary(modelA)$cov.scaled[3, 3]
cov_b1b2 = summary(modelA)$cov.scaled[2, 3]
SE_b1b2 = sqrt(var_b1 + var_b2 + 2*cov_b1b2)
SE_b1b2
exp(0.226878-0.605891 + c(-1, 1) * 1.96 * SE_b1b2)
modelD = glm(Classification_High ~ Age + Ethnoracial_Group_White1_Asian2 + factor(Class_Self) + Health_General + BMI + Hrs_Screen + Hrs_Outdoor + Hrs_Exercise + Educ_College_Grad + Infected_Any, family = binomial(link = "logit"), data = COVIDdata_NCSU)
summary(modelD)
modelD$deviance - modelA$deviance
pchisq(modelD$deviance-modelA$deviance, df=18-15, lower.tail=FALSE)
model.array=rbind(coef(model1), coef(model2), coef(model3))
model.array=cbind(model.array, c(deviance(model1), deviance(model2), deviance(model3)))
colnames(model.array)=c("Intercept", "log(area+1)","Residual dev.")
rownames(model.array)=c("Logit","Probit","C log-log")
kable(model.array)
rd1 = residuals.glm(model1,"deviance")
fv1 = model1$fitted.values
rd2 = residuals.glm(model2,"deviance")
fv2 = model2$fitted.values
rd3 = residuals.glm(model3,"deviance")
fv3 = model3$fitted.values
plot(fv1,rd1,ylim=c(-4,4), xlab="FITTED VALUES",ylab="RESIDUALS",col=2,pch=16,cex=2)
points(fv2,rd2,col=3,pch=17,cex=2)
points(fv3,rd3,col=4,pch=18,cex=2)
abline(h=-2, lty=2)
abline(h= 2, lty=2)
legend(0,4.4,c("Model 1 Residuals","Model 2 Residuals","Model 3 Residuals"),pch=c(16,17,18), col=c(2,3,4), bty="n")
library(knitr)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=70),tidy=TRUE)
# install.packages("ALSM") Should only need to run once, comment out afterwards
library(ALSM)
data(GroceryRetailer)
str(GroceryRetailer)
m1 = lm(y ~ x1 + x2 + x3, data=GroceryRetailer)
summary(m1)
confint(m1)
# Main effect plots
par(mfrow=c(1,3))
plot(GroceryRetailer$x1, GroceryRetailer$y)
abline(m1$coeff[1], m1$coeff[2])
plot(GroceryRetailer$x2, GroceryRetailer$y)
abline(m1$coeff[1], m1$coeff[3])
plot(GroceryRetailer$x3, GroceryRetailer$y)
abline(m1$coeff[1], m1$coeff[4])
# Residual Plots
par(mfrow=c(2,3))
plot(m1$fitted.values, rstandard(m1), main="Residuals vs Fitted Values", ylim=c(-2.5,2.5), ylab="Standardized Residuals", xlab="Fitted Values")
plot(GroceryRetailer$x1, rstandard(m1), main="Residuals vs X1", ylim=c(-2.5,2.5), ylab="X1 Number of Cases Shipped", xlab="Residuals")
plot(GroceryRetailer$x2, rstandard(m1), main="Residuals vs X2", ylim=c(-2.5,2.5), ylab="X2 Total Labour Hours", xlab="Residuals")
plot(GroceryRetailer$x3, rstandard(m1), main="Residuals vs X3", ylim=c(-2.5,2.5), ylab="X3 Holiday Week", xlab="Residuals")
abline(h=0); abline(h=1.96,lty=3); abline(h=-1.96,lty=3)
lines(lowess(m1$fitted.values, rstandard(m1)),col="red")
qqnorm(rstandard(m1)); abline(0,1)
avg_cases <- mean(GroceryRetailer$x1)
avg_indirect <- mean(GroceryRetailer$x2)
new <- data.frame(x1=avg_cases, x2=avg_indirect, x3=1)
predict(m1, newdata=new, interval='confidence')
interaction_model <- lm(y~x1*x3+x2, data=GroceryRetailer)
summary(interaction_model)
interaction_model <- lm(y~x1+x2*x3, data=GroceryRetailer)
summary(interaction_model)
interaction_model <- lm(y~x1*x2*x3, data=GroceryRetailer)
summary(interaction_model)
interaction_model
m2 = lm(x1+x2+x1*x3+x2+x3, data=GroceryRetailer)
m2 = lm(y~x1+x2+x1*x3+x2+x3, data=GroceryRetailer)
anova(m1, m2)
m2 = lm(y~x1+x2+x3+x1*x3+x2+x3, data=GroceryRetailer)
anova(m1, m2)
m2 = lm(y ~ x1 + x2 + x3 + x1*x3 + x2*x3, data=GroceryRetailer)
anova(m1, m2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(knitr)
library(readr)
library(kableExtra)
library(data.table)
library(ggplot2)
opts_chunk$set(tidy.opts=list(width.cutoff=75))
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
housing <- read_csv("house-prices-advanced-regression-techniques/train.csv")
nrow(housing)
ncol(housing)
# remove column Order since it's just row index
housing <- housing[ , !(names(housing) == "Order")]
# Alley: Type of alley access to property
sum(!is.na(housing$Alley))      # only 198 observations
# Pool.QC: Pool quality
sum(!is.na(housing$Pool.QC))    # only 13 observations
# Misc.Feature: Miscellaneous feature not covered in other categories
sum(!is.na(housing$Misc.Feature)) # only 106 observations
# Fence: Fence quality
sum(!is.na(housing$Fence))  # only 572 observations
# Fireplace.Qu: Fireplace quality
sum(!is.na(housing$Fireplace.Qu)) # only 1508 observations
# remove column alley, pool QC, Misc Feature
drops <- c("Alley","Pool.QC", "Fence", "Misc.Feature")
newHousing <- housing[ , !(names(housing) %in% drops)]
# Check for duplicates in the entire dataset (0 duplicates)
duplicates <- housing[duplicated(housing), ]
dim(duplicates)
summary(housing$SalePrice)
par(mfrow=c(1,2), mai=c(1, 1, 1, 1))
options(scipen=10)
hist(housing$SalePrice, xlab = "Property Sale Price", main = "Histogram of Sale Price")
lines(housing$SalePrice, col = 4, lwd = 2)
par(new=TRUE)
plot(density(housing$SalePrice), col=2, lwd = 2, yaxt="n", xaxt="n",
bty='n', xlab="", ylab="", main='')
axis(4, las=1)
hist(log(housing$SalePrice), xlab = "log(Sale Price)", main = "Histogram of log(Sale Price)", breaks = 20)
par(new=TRUE)
plot(density(log(housing$SalePrice)), col=2, lwd = 2, yaxt="n", xaxt="n",
bty='n', xlab="", ylab="", main='')
axis(4, las=1)
# Subset of numeric columns
numericHousingData <- newHousing[, sapply(newHousing, is.numeric)]
# Calculate the correlations between each numeric column and the response variable
correlations <- cor(numericHousingData[, -which(names(numericHousingData) == "SalePrice")],
numericHousingData$SalePrice, use = "complete.obs")
# rank the correlations into two groups (positive and negative)
posCorrelations <- correlations[correlations[,1] >= 0, ]
negCorrelations <- correlations[correlations[,1] < 0, ]
# Print the correlations
print(sort(posCorrelations,decreasing=TRUE))
print(sort(negCorrelations,decreasing=FALSE))
cor_matrix <- cor(numericHousingData, use = "complete.obs")
corr_df = data.frame(cor_matrix)
corr_df$var = row.names(corr_df)
# Positive
corr_df1 = reshape2::melt(corr_df, value_name = "Corr")
corr_df1 = corr_df1[(corr_df1$value > 0.7 & corr_df1$value < 1),]
print(corr_df1[order(corr_df1$value,decreasing=TRUE),])
maxpos <- corr_df1[order(corr_df1$value),]
# Negative
corr_df2 = reshape2::melt(corr_df, value_name = "Corr")
corr_df2 = corr_df2[(corr_df2$value < -0.7 & corr_df2$value > -1),]
print(corr_df2[order(corr_df2$value,decreasing=TRUE),])
maxneg <- corr_df2[order(corr_df2$value),]
# Correlation matrix including only the top positive and negative correlations
names <- c(maxpos$var, maxneg$var)
topcormat <- cor_matrix[names, names]
# plot the correlation matrix
# install.packages('corrplot')
library(corrplot)
corrplot(topcormat, method='color', tl.cex=0.5)
ggplot(housing, aes(x=Neighborhood,y=SalePrice)) + geom_boxplot(color="black", fill="yellow")+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
as.data.frame(table(housing$Street))
as.data.frame(table(housing$Utilities))
as.data.frame(table(housing$Roof.Matl))
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(knitr)
library(readr)
library(kableExtra)
library(data.table)
library(ggplot2)
opts_chunk$set(tidy.opts=list(width.cutoff=75))
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
housing <- read_csv("house-prices-advanced-regression-techniques/train.csv")
nrow(housing)
ncol(housing)
# remove column Order since it's just row index
housing <- housing[ , !(names(housing) == "Order")]
# Alley: Type of alley access to property
sum(!is.na(housing$Alley))      # only 198 observations
# Pool.QC: Pool quality
sum(!is.na(housing$Pool.QC))    # only 13 observations
# Misc.Feature: Miscellaneous feature not covered in other categories
sum(!is.na(housing$Misc.Feature)) # only 106 observations
# Fence: Fence quality
sum(!is.na(housing$Fence))  # only 572 observations
# Fireplace.Qu: Fireplace quality
sum(!is.na(housing$Fireplace.Qu)) # only 1508 observations
# remove column alley, pool QC, Misc Feature
drops <- c("Alley","Pool.QC", "Fence", "Misc.Feature")
newHousing <- housing[ , !(names(housing) %in% drops)]
# Check for duplicates in the entire dataset (0 duplicates)
duplicates <- housing[duplicated(housing), ]
dim(duplicates)
summary(housing$SalePrice)
par(mfrow=c(1,2), mai=c(1, 1, 1, 1))
options(scipen=10)
hist(housing$SalePrice, xlab = "Property Sale Price", main = "Histogram of Sale Price")
lines(housing$SalePrice, col = 4, lwd = 2)
par(new=TRUE)
plot(density(housing$SalePrice), col=2, lwd = 2, yaxt="n", xaxt="n",
bty='n', xlab="", ylab="", main='')
axis(4, las=1)
hist(log(housing$SalePrice), xlab = "log(Sale Price)", main = "Histogram of log(Sale Price)", breaks = 20)
par(new=TRUE)
plot(density(log(housing$SalePrice)), col=2, lwd = 2, yaxt="n", xaxt="n",
bty='n', xlab="", ylab="", main='')
axis(4, las=1)
# Subset of numeric columns
numericHousingData <- newHousing[, sapply(newHousing, is.numeric)]
# Calculate the correlations between each numeric column and the response variable
correlations <- cor(numericHousingData[, -which(names(numericHousingData) == "SalePrice")],
numericHousingData$SalePrice, use = "complete.obs")
# rank the correlations into two groups (positive and negative)
posCorrelations <- correlations[correlations[,1] >= 0, ]
negCorrelations <- correlations[correlations[,1] < 0, ]
# Print the correlations
print(sort(posCorrelations,decreasing=TRUE))
print(sort(negCorrelations,decreasing=FALSE))
cor_matrix <- cor(numericHousingData, use = "complete.obs")
corr_df = data.frame(cor_matrix)
corr_df$var = row.names(corr_df)
# Positive
corr_df1 = reshape2::melt(corr_df, value_name = "Corr")
corr_df1 = corr_df1[(corr_df1$value > 0.7 & corr_df1$value < 1),]
print(corr_df1[order(corr_df1$value,decreasing=TRUE),])
maxpos <- corr_df1[order(corr_df1$value),]
# Negative
corr_df2 = reshape2::melt(corr_df, value_name = "Corr")
corr_df2 = corr_df2[(corr_df2$value < -0.7 & corr_df2$value > -1),]
print(corr_df2[order(corr_df2$value,decreasing=TRUE),])
maxneg <- corr_df2[order(corr_df2$value),]
# Correlation matrix including only the top positive and negative correlations
names <- c(maxpos$var, maxneg$var)
topcormat <- cor_matrix[names, names]
# plot the correlation matrix
# install.packages('corrplot')
library(corrplot)
corrplot(topcormat, method='color', tl.cex=0.5)
ggplot(housing, aes(x=Neighborhood,y=SalePrice)) + geom_boxplot(color="black", fill="yellow")+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
as.data.frame(table(housing$Street))
as.data.frame(table(housing$Utilities))
as.data.frame(table(housing$Roof.Matl))
setwd("~/Library/CloudStorage/OneDrive-UniversityofWaterloo/School/University/Year 4/4B/STAT 444/Final Project/STAT 444 FINAL PROJECT PROPOSAL")
