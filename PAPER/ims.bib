@article{cock2011amesdataset,
  author = {Dean De Cock},
  title = {Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project},
  journal = {Journal of Statistics Education},
  volume = {19},
  number = {3},
  year  = {2011},
  publisher = {Taylor & Francis},
  doi = {10.1080/10691898.2011.11889627},
  URL = {https://doi.org/10.1080/10691898.2011.11889627},
  eprint = {https://doi.org/10.1080/10691898.2011.11889627}
}

@article{JSSv033i01,
 title={Regularization Paths for Generalized Linear Models via Coordinate Descent},
 volume={33},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v033i01},
 doi={10.18637/jss.v033.i01},
 abstract={We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include ℓ&amp;lt;sub&amp;gt;1&amp;lt;/sub&amp;gt; (the lasso), ℓ&amp;lt;sub&amp;gt;2&amp;lt;/sub&amp;gt; (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
 number={1},
 journal={Journal of Statistical Software},
 author={Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
 year={2010},
 pages={1–22}
}

@book{hastie01statisticallearning,
  added-at = {2010-06-03T15:15:09.000+0200},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/200d858c0bd2826d4eb5f39450192d1f5/ukoethe},
  edition = 2,
  file = {:Books\\HastieTibshiraniFriedman-09-Elements-of-Statistical-Learning-2nd-edition\\hastie_09_elements-of.statistical-learning.pdf:PDF},
  interhash = {52d1772f39be836e3b298d37b8c0cfa1},
  intrahash = {00d858c0bd2826d4eb5f39450192d1f5},
  keywords = {inference mathmatics dataanalysis method clutering statistics},
  publisher = {Springer},
  timestamp = {2010-06-03T15:15:09.000+0200},
  title = {The elements of statistical learning: data mining, inference and prediction},
  url = {http://www-stat.stanford.edu/~tibs/ElemStatLearn/},
  year = 2009
}



@article{quinlaninduction,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Quinlan, J. R.},
  biburl = {https://www.bibsonomy.org/bibtex/24b1ef1c16c39d56f0f132c191870d776/schaul},
  citeulike-article-id = {2378698},
  description = {idsia},
  interhash = {3fe7356363a918dd24aeba82ba71d75a},
  intrahash = {4b1ef1c16c39d56f0f132c191870d776},
  journal = {Machine Learning},
  keywords = {nn},
  pages = {81--106},
  priority = {2},
  timestamp = {2008-02-26T12:02:56.000+0100},
  title = {Induction of Decision Trees},
  volume = 1,
  year = 1986
}

@article{thinplateregressionsplines,
    author = {Wood, Simon N.},
    title = "{Thin Plate Regression Splines}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {65},
    number = {1},
    pages = {95-114},
    year = {2003},
    month = {01},
    abstract = "{I discuss the production of low rank smoothers for d ≥ 1 dimensional data, which can be fitted by regression or penalized regression methods. The smoothers are constructed by a simple transformation and truncation of the basis that arises from the solution of the thin plate spline smoothing problem and are optimal in the sense that the truncation is designed to result in the minimum possible perturbation of the thin plate spline smoothing problem given the dimension of the basis used to construct the smoother. By making use of Lanczos iteration the basis change and truncation are computationally efficient. The smoothers allow the use of approximate thin plate spline models with large data sets, avoid the problems that are associated with ‘knot placement’ that usually complicate modelling with regression splines or penalized regression splines, provide a sensible way of modelling interaction terms in generalized additive models, provide low rank approximations to generalized smoothing spline models, appropriate for use with large data sets, provide a means for incorporating smooth functions of more than one variable into non-linear models and improve the computational efficiency of penalized likelihood models incorporating thin plate splines. Given that the approach produces spline-like models with a sparse basis, it also provides a natural way of incorporating unpenalized spline-like terms in linear and generalized linear models, and these can be treated just like any other model terms from the point of view of model selection, inference and diagnostics.}",
    issn = {1369-7412},
    doi = {10.1111/1467-9868.00374},
    url = {https://doi.org/10.1111/1467-9868.00374},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/65/1/95/49799823/jrsssb\_65\_1\_95.pdf},
}



